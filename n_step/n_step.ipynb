{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-27 13:33:55,550] You have 'numpy' version 1.10.1 installed, but 'gym' requires at least 1.10.4. HINT: upgrade via 'pip install -U numpy'.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "from gym.envs.toy_text import discrete\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomWalk(discrete.DiscreteEnv):\n",
    "    metadata = {'render.modes':['human','ansi']}\n",
    "    def __init__(self):\n",
    "        self.shape = (7,)\n",
    "        nS = np.prod(self.shape)\n",
    "        nA = 2\n",
    "        # calculate transition probabilities\n",
    "        self.LEFT = 0\n",
    "        self.RIGHT = 1\n",
    "        P = {}\n",
    "        for s in range(nS):\n",
    "            P[s] = {a : [] for a in range(nA) }\n",
    "            # observation, new_state, reward, is_done\n",
    "            P[s][self.LEFT] = [(1.0, max(0, s-1), 0, True if max(0, s-1) == 0 else False)]\n",
    "            P[s][self.RIGHT] = [(1.0, min(nS-1, s+1), 0, True if min(nS-1,s+1) == (nS-1) else False)]\n",
    "        # the transition from E to RT is 1\n",
    "        P[5][self.RIGHT] = [(1.0, 6, 1, True)]\n",
    "        \n",
    "        # we always start in state C (which is 3)\n",
    "        isd = np.zeros(nS)\n",
    "        isd[3] = 1.0\n",
    "        \n",
    "        super(RandomWalk, self).__init__(nS, nA, P, isd)\n",
    "        \n",
    "    def _step(self, a):\n",
    "        transitions = self.P[self.s][a]\n",
    "        p, s, r, d = transitions[0]\n",
    "        self.s = s\n",
    "        self.lastaction=a\n",
    "        return (s, r, d, {\"prob\" : p})\n",
    "    \n",
    "    def _render(self, mode='human', close=False):\n",
    "        if close:\n",
    "            return\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "        st = ['LT', 'A', 'B', 'C', 'D', 'E', 'RT']\n",
    "        st[self.s] = '(' + st[self.s] + ')'\n",
    "        outfile.write(\" \".join(st))\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the game when we go all left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LT A B (C) D E RT\n",
      "(2, 0, False, {'prob': 1.0})\n",
      "LT A (B) C D E RT\n",
      "(1, 0, False, {'prob': 1.0})\n",
      "LT (A) B C D E RT\n"
     ]
    }
   ],
   "source": [
    "env = RandomWalk()\n",
    "env.render()\n",
    "print env.step(0)\n",
    "env.render()\n",
    "print env.step(0)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the game when we go all right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LT A B (C) D E RT\n",
      "(4, 0, False, {'prob': 1.0})\n",
      "LT A B C (D) E RT\n",
      "(5, 0, False, {'prob': 1.0})\n",
      "LT A B C D (E) RT\n",
      "(6, 1, True, {'prob': 1.0})\n"
     ]
    }
   ],
   "source": [
    "env = RandomWalk()\n",
    "env.render()\n",
    "print env.step(1)\n",
    "env.render()\n",
    "print env.step(1)\n",
    "env.render()\n",
    "print env.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the algorithm for an n-step policy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_step_td_estimate(env, policy, num_episodes, alpha, gamma, n, debug=False):\n",
    "    # intialise V(s) arbitrarily\n",
    "    V = np.zeros(env.nS)\n",
    "    # repeat for each episode\n",
    "    for num_episode in range(num_episodes):\n",
    "        if debug:\n",
    "            print \"iter:\", num_episode\n",
    "        env.reset()\n",
    "        T = np.inf\n",
    "        rewards = dict() # TODO: not efficient\n",
    "        states = dict()\n",
    "        states[0] = env.s\n",
    "        for t in itertools.count():\n",
    "            #print t, states, V\n",
    "            if t < T:\n",
    "                # take an action according to the policy\n",
    "                action = policy(env.s)\n",
    "                _, R, is_done, _ = env.step(action)\n",
    "                # observe and store the next reward as R_{t+1}, and the next state as S_{t+1}\n",
    "                rewards[t+1] = R\n",
    "                states[t+1] = env.s\n",
    "                # if S_{t+1} is terminal, then T = t - 1\n",
    "                if is_done:\n",
    "                    T = t+1\n",
    "            tau = t - n + 1\n",
    "            #print tau\n",
    "            if tau >= 0:\n",
    "                if debug:\n",
    "                    print \"updating state %i,\" % states[tau],\n",
    "                G = 0\n",
    "                for i in range(tau+1, min(tau+n, T)+1):\n",
    "                    G += ((gamma**(i-tau-1))*rewards[i])\n",
    "                if tau + n < T:\n",
    "                    G = G + (gamma**n)*V[ states[tau+n] ]\n",
    "                if debug:\n",
    "                    print \"G = %i,\" % G,\n",
    "                    print \"V of state %i is %f\" % (states[tau], V[states[tau]])\n",
    "                V[ states[tau] ] += alpha*(G - V[ states[tau] ])\n",
    "            if tau == T-1:\n",
    "                break\n",
    "    if debug:\n",
    "        print\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're following an always-right-walk policy, we expect that all states to the right of C receive a value of 1 (since whenever we are in these states, we will move right eventually hitting the terminal with a reward of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def right_walk_policy(state):\n",
    "    LEFT, RIGHT = 0, 1\n",
    "    return RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_td_estimate(env=RandomWalk(), policy=right_walk_policy, num_iters=100, alpha=0.5, gamma=1, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def left_walk_policy(state):\n",
    "    LEFT, RIGHT = 0, 1\n",
    "    return LEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_td_estimate(env=RandomWalk(), policy=left_walk_policy, num_iters=100, alpha=0.5, gamma=1, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try a random walk policy with $n=2$ and $n=1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_policy(state):\n",
    "    LEFT, RIGHT = 0, 1\n",
    "    if np.random.randint(0,2) == 0:\n",
    "        return LEFT\n",
    "    else:\n",
    "        return RIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n = 2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18261455  0.34008082  0.49672043  0.66335435  0.83086432]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "V = n_step_td_estimate(env=RandomWalk(), policy=random_policy, num_iters=10000, alpha=0.01, gamma=1, n=2)\n",
    "print V[ [1,2,3,4,5] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the textbook, the real values are (1/6, 2/6, 3/6, 4/6, and 5/6) for A, B, C, D, and E, respectively, so let's check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "print [1.0/6, 2.0/6, 3.0/6, 4.0/6, 5.0/6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n = 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17417513  0.33827588  0.49017577  0.66800682  0.83955003]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "V = n_step_td_estimate(env=RandomWalk(), policy=random_policy, num_iters=10000, alpha=0.01, gamma=1, n=1)\n",
    "print V[ [1,2,3,4,5] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the textbook, \"a one-step method would change only the estimate for the last state, V(E), which would be incremented toward 1, the observed return\". This is because we go from C to D (immediate reward = 0), from D to E ( immediate reward = 0), and E to terminal (immediate reward = 1), so E only gets updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "updating state 3, G = 0, V of state 3 is 0.000000\n",
      "updating state 4, G = 0, V of state 4 is 0.000000\n",
      "updating state 5, G = 1, V of state 5 is 0.000000\n",
      "\n",
      "[ 0.    0.    0.    0.    0.    0.01  0.  ]\n"
     ]
    }
   ],
   "source": [
    "V = n_step_td_estimate(env=RandomWalk(), policy=right_walk_policy, num_iters=1, alpha=0.01, gamma=1, n=1, debug=True)\n",
    "print V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...where state 3 = 'C', state 4 = 'D', and state 5 = 'E'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the textbook, \"a two step method, on the other hand, would increment the values of the two states preceding termination: V(D) and V(E)\". This is because the immediate reward from D to the terminal state is 1, and also because the immediate reward from E to the terminal state is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "updating state 3, G = 0, V of state 3 is 0.000000\n",
      "updating state 4, G = 1, V of state 4 is 0.000000\n",
      "updating state 5, G = 1, V of state 5 is 0.000000\n",
      "\n",
      "[ 0.    0.    0.    0.    0.01  0.01  0.  ]\n"
     ]
    }
   ],
   "source": [
    "V = n_step_td_estimate(env=RandomWalk(), policy=right_walk_policy, num_iters=1, alpha=0.01, gamma=1, n=2, debug=True)\n",
    "print V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a trade-off to be made for $n$: in the extreme case, we perform Monte-Carlo updates, and then we perform updates on the state values extremely late (i.e. after we have hit the terminal state). In the other extreme case ($n=1$), we perform updates after single steps, which doesn't seem all that ideal, since we are computing updates based on very little information (in this case, simply the immedate reward, $R_{t+1}$), and the estimated value for $S_{t+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExtremeRandomWalk(discrete.DiscreteEnv):\n",
    "    metadata = {'render.modes':['human','ansi']}\n",
    "    def __init__(self):\n",
    "        num_states = 19\n",
    "        self.shape = (num_states,)\n",
    "        nS = np.prod(self.shape)\n",
    "        nA = 2\n",
    "        # calculate transition probabilities\n",
    "        self.LEFT = 0\n",
    "        self.RIGHT = 1\n",
    "        P = {}\n",
    "        for s in range(nS):\n",
    "            P[s] = {a : [] for a in range(nA) }\n",
    "            # observation, new_state, reward, is_done\n",
    "            P[s][self.LEFT] = [(1.0, max(0, s-1), 0, True if max(0, s-1) == 0 else False)]\n",
    "            P[s][self.RIGHT] = [(1.0, min(nS-1, s+1), 0, True if min(nS-1,s+1) == (nS-1) else False)]\n",
    "        # the transition from the left-most state to the left terminal is a reward of 1\n",
    "        P[1][self.LEFT] = [(1.0, 0, 1, True)]\n",
    "        \n",
    "        # we always start in state C (which is 3)\n",
    "        isd = np.zeros(nS)\n",
    "        isd[9] = 1.0\n",
    "        \n",
    "        super(ExtremeRandomWalk, self).__init__(nS, nA, P, isd)\n",
    "        \n",
    "    def _step(self, a):\n",
    "        transitions = self.P[self.s][a]\n",
    "        p, s, r, d = transitions[0]\n",
    "        self.s = s\n",
    "        self.lastaction=a\n",
    "        return (s, r, d, {\"prob\" : p})\n",
    "    \n",
    "    def _render(self, mode='human', close=False):\n",
    "        if close:\n",
    "            return\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "        st = [ str(x) for x in range(self.nS) ]\n",
    "        st[self.s] = '(' + st[self.s] + ')'\n",
    "        outfile.write(\" \".join(st))\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.94444444  0.88888889  0.83333333  0.77777778  0.72222222\n",
      "  0.66666667  0.61111111  0.55555556  0.5         0.44444444  0.38888889\n",
      "  0.33333333  0.27777778  0.22222222  0.16666667  0.11111111  0.05555556\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "tmp=ExtremeRandomWalk()\n",
    "real_vals = []\n",
    "for i in range(1, tmp.nS-2+1):\n",
    "    real_vals.append( (i*1.0) / (tmp.nS-1) )\n",
    "real_vals = [0] + real_vals[::-1] + [0]\n",
    "real_vals = np.asarray(real_vals)\n",
    "print real_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.249317645224\n",
      "2 0.208274428675\n",
      "3 0.179403925484\n",
      "4 0.147520342963\n",
      "5 0.129283483399\n",
      "6 0.1112906734\n",
      "7 0.0988563961121\n",
      "8 0.0944361213997\n",
      "9 0.0900622712431\n",
      "10 0.0936641192097\n",
      "11 0.103183547782\n",
      "12 0.109970136606\n",
      "13 0.126749801925\n",
      "14 0.13945249649\n",
      "15 0.19002149287\n",
      "16 0.200376455816\n",
      "17 0.194688233\n",
      "18 0.248180260762\n"
     ]
    }
   ],
   "source": [
    "mses = []\n",
    "for n in range(1, env.nS):\n",
    "    V = np.zeros(tmp.nS)\n",
    "    num_repeats = 100\n",
    "    for repeat in range(num_repeats):\n",
    "        V += n_step_td_estimate(env=ExtremeRandomWalk(), policy=random_policy, num_episodes=10, alpha=0.01, gamma=1, n=n, debug=False)\n",
    "    V = np.sum(V, axis=0) / num_repeats\n",
    "    mse = np.mean((V - real_vals)**2)\n",
    "    print n, mse\n",
    "    mses.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x114db15d0>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUGr+lxbZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114d84550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mses)\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12728053037252715"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((V - real_vals)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
